TABLE OF CONTENTS
=================

1.  Overview
2.  The Parser
3.  The Weeder

OVERVIEW
========

The parser and the weeder make up the syntactical front-end of the
compiler. Together they transform raw textual input into an internal
representation of a Java program - or reject the input as illegal
Java!

Orchestrating a parsing and a weeding phase together comes to a choice
of where to place responsibility. Some things are inherently not
parseable by a LR(1) parser and must be dealt with in the weeder,
while things that might be weeded could be rejected at parse-time. 

For instance, cast expressions were too detailed to handle in the
parser - as detailed below - while illegal `instanceof` operations with a
primitive type as right hand operand can be rejected by the parser.

The decision comes down to wether to expend the effort on molding the
grammar to fit, or to leverage the full power of turing complete OCaml
in the weeder. This is the criterion we used in implementing this
phase.

THE PARSER
==========
Changes comitted to the parser are described below:

FIELDS 
------

Fields are easy to parse and no shift-reduce errors occured. We
introduced the following field-declaration:

field_declaration
  :  access typeexp IDENTIFIER SEMICOLON
  { make_field $startpos($3) ($1,false,false,$2,$3,None) }
  | access typeexp IDENTIFIER ASSIGN expression SEMICOLON
      { make_field $startpos($3) ($1,false,false,$2,$3,Some $5)}
  ;

and changed the member-declaration to also match on the
field_declaration. This seemed like a simple introduction to changing
the parser, so we will not discuss this change further

INSTANCEOF
---------- 

We decided to implement the instanceof as a relational-expression
according to the provided java specification - this is the way we
match for InstanceOf
  
  |  relational_expression INSTANCEOF complex_type (IS THIS CORRECT, should it be primitive_type)
      { make_exp $startpos (Ast.Instanceof($1,$3))}


POSSIBLE CAST
-------------

Cast-expression was the first hard challenge to
overcome. First we tried with a naive approach:

cast_expression
  : L_PAREN element_type R_PAREN expression
    { make_exp $startpos (Ast.Cast($2, $4)) } 
  ; 

Here we got reduce/reduce errors because element_type contains a name,
and so does Lvalue, so the one-token lookahead parser could not
distinguish between the two cases. To help the parser, we explicitly
describe each type-case a cast-expression could have - either a
primitive type, array_type or expression. We cannot be certain
expression is in fact a cast-expression and to solve this problem, we
decided to introduce PossibleCast to the Ast and let the weeder do
some work:

cast_expression
  : L_PAREN expression R_PAREN unary_expression_not_plus_minus
    { make_exp $startpos (Ast.PossiblyCast($2, $4)) } 
  | L_PAREN array_type R_PAREN unary_expression_not_plus_minus
    { make_exp $startpos (Ast.Cast($2, $4)) } 
  | L_PAREN primitive_type R_PAREN unary_expression
    { make_exp $startpos (Ast.Cast($2, $4)) }
  ; 

Notice, that the java-spec mandates cast of complex-types to have a
right-hand-side of unary_expression_not_plus_minus.
  
SIMPLE FOR STATEMENTS
---------------------

We can describe simple for statements as a while expression, but one
need to be aware of scopes. for (int i = 0; exp; update) { body }
could be describe like this: {int i = 0 {while (expr) { body; update
}. No problems will arise, if the init is not empty. But it can be
empty, thus the body can introduce a second variable i, that could
clash with the update-statement. Therefore, we need to introduce
another block in the while body - like this:

{int i = 0 
	while (expr) {
		{ body }
		update
	}
} 

The implementation is pretty simple, there are one for no short if and
one for the other case:

for_statement
  :  FOR L_PAREN for_init SEMICOLON for_condition SEMICOLON for_update R_PAREN statement 
    { let for_init_var = $3 in
      let for_update_var = make_stm $startpos($7) (Ast.Block [$7]) in
      let while_inner_raw = $9 in
      let while_inner_body =
	match while_inner_raw with
	  | { Ast.stm = Ast.Block _ } ->
	    while_inner_raw
	  | _ -> 
	    make_stm $startpos($9) (Ast.Block [while_inner_raw]) in
      let while_body = make_stm $startpos($9) (Ast.Block [while_inner_body;for_update_var]) in
      let while_exp = make_stm $startpos($5) (Ast.While($5,while_body)) in
      
      make_stm $startpos (Ast.Block [for_init_var; while_exp])
    }	       
  ;
  
Notice, that the statement ($9) could return a single statement and
not a block - to make sure, that the update-statement does not
interact with the inner-body, we manually create the block if it does
not exist.

ARRAY ACCESS
------------

To solve array-access we first introduced a '[]' token in the lexer -
this solved all problems with clashing, but was not allowed for online
tests. So another solution was required. Let us first introduce our
function for array_access:

array_access
  :  primary_not_name_no_new_array L_BRACKET expression R_BRACKET
  { make_lvalue $startpos($1) (Ast.Array($1,$3)) }
  | name L_BRACKET expression R_BRACKET
     { make_lvalue $startpos($1) (Ast.Array(make_exp $startpos($1) (Ast.Lvalue (make_lvalue $startpos($1) (Ast.AmbiguousName $1))) ,$3)) }
;

If we did not match on primary_not_name_no_new_array, we would recieve
two reduce errors, one regarding the parsers inability to distinguish
between array-creation ( int [ <- ) and one for naming in the left
hand side. Therefor we have an explicit name case in array_access and
call a specific function, where no array can be created in the same
recursion-step (no_array part) or no ambigous-name clashing
(primary_not_name) part. Below is the primary_not_name_no_new_array:

primary_not_name
  : primary_not_name_no_new_array
   { $1 }
  |  array_creation_expression
     { $1 }
  ;    

primary_not_name_no_new_array
  :  literal
     { $1 }
  |  THIS
     { make_exp $startpos (Ast.This) }
  |  left_hand_side_not_name
     { make_exp $startpos (Ast.Lvalue $1) }
  |  L_PAREN expression R_PAREN
     { make_exp $startpos (Ast.InnerExp $2) }
  |  class_instance_creation_expression
     { $1 }
  |  method_invocation
     { $1 }
  ;

We were not quite done, we needed to change the array_type to explicit
cases, rathern than use element-type:

array_type 
  :  primitive_type L_BRACKET R_BRACKET
     { make_typeexp $startpos (Ast.TArray $1) }
  |  name L_BRACKET R_BRACKET
     { make_typeexp $startpos (Ast.TArray (make_typeexp $startpos (Ast.Named $1))) }
  ;

This works and there are no reduce/recude errors.  

FINAL, STATIC AND ABSTRACT MODIFIERS
------------------------------------

It is clear, that if a method is declared abstract, it cannot be final
or static, so this is what we did:

method_declaration
  :  access method_modifiers typeexp IDENTIFIER method_params throws_clause opt_method_body
     { let (ab, (stat, fin)) = $2 in
       make_method $startpos($4) ($1,stat,fin,ab,$3,$4,$5,$6,$7) }
  |  access typeexp IDENTIFIER method_params throws_clause opt_method_body
     { make_method $startpos($3) ($1,false,false,false,$2,$3,$4,$5,$6) }
;

method_modifiers
  : ABSTRACT 
  { true, (false, false)}
  | method_modifiers_not_abstract
  { false, $1 }
  ;

method_modifiers_not_abstract
  : FINAL
    {false, true}
  | STATIC
    {true, false}
  | FINAL STATIC 
      {true, true}
  | STATIC FINAL
      {true, true}
;

When doing it like this, we get no reduce errors, because both method declarations are explicitly declared.

INNER EXPRESSION
----------------

After doing parsing and weeding, we realized, that expressions were
being moved up in the thee if it was paranthesized:

(((name)))obj -> (name)obj

This makes weeding a big problem, so to overcome this obstacle, we
introduced an inner-expression we later could weed out. In this way,
we could raise invalid syntax errors from the weeder.


THE  WEEDER
===========

Our weeder is architecturally a 2-pass phase: first we traverse the
raw abstract syntax tree and perform all due checks. Secondly, we
traverse the tree again, this time producing a Weeded ast, under the
precondition that the raw AST passed all checks.

This has the benefit of code clarity: there is a clear purpose in all
parts of the code, and never are the multiple things happening at
once.

The added clarity does of course come at a cost. For instance, a
single check could not be completed untill after the transformation (a
case of negated integer literals), and the weeder actually performs
the transformation, checks the transformed node, discards it and then
transforms it again in the second pass - with the guarantee that the
transformation is sound.

While preconditions often simplify code, it does in a couple of cases
add some unnecessary match-branches in our transformation pass. For
instance, the first pass ensures that all of our `PossiblyCast` nodes
contain only an `AmbiguousName` as target type - but this information
is lost between the too passes, which would have been avoided by
combining the two passes. Instead, we must reject - _again!_ - all
illegal PossiblyCasts as a breach of precondition.
